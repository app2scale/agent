En iyi sonu√ß: Result(
  metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 28.92768740852674, 'cur_kl_coeff': 1.0691058840368785e-51, 'cur_lr': 0.00010000000000000003, 'total_loss': 8.359676698843638, 'policy_loss': -0.0038090700943333405, 'vf_loss': 8.363485739628475, 'vf_explained_var': -0.003219421704610189, 'kl': 0.003088108198409993, 'entropy': 0.16489511439576746, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 128.0, 'num_grad_updates_lifetime': 59880.5, 'diff_num_grad_updates_vs_sampler_policy': 119.5}}, 'num_env_steps_sampled': 256000, 'num_env_steps_trained': 256000, 'num_agent_steps_sampled': 256000, 'num_agent_steps_trained': 256000}, 'sampler_results': {'episode_reward_max': 68.77681238771433, 'episode_reward_min': 46.38680953683729, 'episode_reward_mean': 61.529014061322435, 'episode_len_mean': 100.0, 'episode_media': {}, 'episodes_this_iter': 12, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [64.55569605680951, 56.53435257019049, 65.55263130754763, 61.88909431241667, 63.83937099033334, 61.96487291985712, 67.86384449685713, 62.65193612358731, 57.32270870876786, 56.98726799419047, 63.016459363952386, 61.82013355849999, 65.62334559638097, 67.6369989404286, 57.64742165248013, 61.01816585876188, 62.589339908285694, 63.35007399436903, 63.65734324642857, 62.99463557868254, 68.77681238771433, 67.41977559588096, 61.91814746466662, 59.87153069749999, 60.38595320780948, 59.74396098505951, 63.413669027999994, 59.76339690167858, 63.419646126666656, 58.73688525038092, 60.27636812230158, 60.46241241583331, 62.36480751147618, 58.58798753666668, 58.80790208730158, 63.4136029140476, 59.30890503509522, 63.973330019333304, 59.821761718190444, 57.31673221340476, 61.94866891723812, 66.2005750151905, 64.31371656480952, 67.64643746466665, 62.81804771542856, 61.72996048611907, 56.873304276999995, 55.477320079714275, 61.72930568752378, 62.41356818164287, 66.58838258638096, 59.70797045478571, 57.885298066249995, 52.74136415304165, 64.95553906521428, 66.97765323891664, 62.35140106457144, 54.80562530574599, 62.077615886738094, 64.08729611502379, 61.437538999666685, 63.80916088199999, 54.818896932809515, 66.01187078633335, 59.62504132716666, 58.439276982666684, 60.510420863119016, 66.0796841288333, 64.45549743, 64.58427734709525, 64.92832585006546, 46.38680953683729, 62.288349706499986, 62.87597523776188, 62.51093101333334, 62.110455159380955, 57.697096100011926, 65.48896409533333, 58.900783951666675, 65.21661438033335, 60.65551730669643, 56.6744269963333, 61.581295697309535, 62.08971820290476, 54.90505574104761, 58.704348663761884, 64.72947626966662, 59.64773236413095, 62.116581138, 62.983852218666655, 60.75418889042856, 53.31020345592859, 65.63772622333332, 58.40115280683135, 63.611003300333344, 60.36445944428572, 60.1883722614286, 64.81527483400001, 60.391244636285705, 63.53547424611904], 'episode_lengths': [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1862092587966596, 'mean_inference_ms': 0.5801499179365308, 'mean_action_processing_ms': 0.0730547639354403, 'mean_env_wait_ms': 0.48841559422092473, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0033164024353027344, 'StateBufferConnector_ms': 0.0025823116302490234, 'ViewRequirementAgentConnector_ms': 0.0633080005645752}}, 'episode_reward_max': 68.77681238771433, 'episode_reward_min': 46.38680953683729, 'episode_reward_mean': 61.529014061322435, 'episode_len_mean': 100.0, 'episodes_this_iter': 12, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [64.55569605680951, 56.53435257019049, 65.55263130754763, 61.88909431241667, 63.83937099033334, 61.96487291985712, 67.86384449685713, 62.65193612358731, 57.32270870876786, 56.98726799419047, 63.016459363952386, 61.82013355849999, 65.62334559638097, 67.6369989404286, 57.64742165248013, 61.01816585876188, 62.589339908285694, 63.35007399436903, 63.65734324642857, 62.99463557868254, 68.77681238771433, 67.41977559588096, 61.91814746466662, 59.87153069749999, 60.38595320780948, 59.74396098505951, 63.413669027999994, 59.76339690167858, 63.419646126666656, 58.73688525038092, 60.27636812230158, 60.46241241583331, 62.36480751147618, 58.58798753666668, 58.80790208730158, 63.4136029140476, 59.30890503509522, 63.973330019333304, 59.821761718190444, 57.31673221340476, 61.94866891723812, 66.2005750151905, 64.31371656480952, 67.64643746466665, 62.81804771542856, 61.72996048611907, 56.873304276999995, 55.477320079714275, 61.72930568752378, 62.41356818164287, 66.58838258638096, 59.70797045478571, 57.885298066249995, 52.74136415304165, 64.95553906521428, 66.97765323891664, 62.35140106457144, 54.80562530574599, 62.077615886738094, 64.08729611502379, 61.437538999666685, 63.80916088199999, 54.818896932809515, 66.01187078633335, 59.62504132716666, 58.439276982666684, 60.510420863119016, 66.0796841288333, 64.45549743, 64.58427734709525, 64.92832585006546, 46.38680953683729, 62.288349706499986, 62.87597523776188, 62.51093101333334, 62.110455159380955, 57.697096100011926, 65.48896409533333, 58.900783951666675, 65.21661438033335, 60.65551730669643, 56.6744269963333, 61.581295697309535, 62.08971820290476, 54.90505574104761, 58.704348663761884, 64.72947626966662, 59.64773236413095, 62.116581138, 62.983852218666655, 60.75418889042856, 53.31020345592859, 65.63772622333332, 58.40115280683135, 63.611003300333344, 60.36445944428572, 60.1883722614286, 64.81527483400001, 60.391244636285705, 63.53547424611904], 'episode_lengths': [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1862092587966596, 'mean_inference_ms': 0.5801499179365308, 'mean_action_processing_ms': 0.0730547639354403, 'mean_env_wait_ms': 0.48841559422092473, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0033164024353027344, 'StateBufferConnector_ms': 0.0025823116302490234, 'ViewRequirementAgentConnector_ms': 0.0633080005645752}, 'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 256000, 'num_agent_steps_trained': 256000, 'num_env_steps_sampled': 256000, 'num_env_steps_trained': 256000, 'num_env_steps_sampled_this_iter': 1024, 'num_env_steps_trained_this_iter': 1024, 'num_steps_trained_this_iter': 1024, 'agent_timesteps_total': 256000, 'timers': {'training_iteration_time_ms': 1562.912, 'sample_time_ms': 712.732, 'load_time_ms': 0.187, 'load_throughput': 5478973.461, 'learn_time_ms': 845.79, 'learn_throughput': 1210.703, 'synch_weights_time_ms': 3.745}, 'counters': {'num_env_steps_sampled': 256000, 'num_env_steps_trained': 256000, 'num_agent_steps_sampled': 256000, 'num_agent_steps_trained': 256000}, 'done': True, 'trial_id': '49c0d_00208', 'perf': {'cpu_util_percent': 63.13333333333333, 'ram_util_percent': 79.7}, 'experiment_tag': '208_clip_param=0.2000,entropy_coeff=0,lambda=1,lr=0.0001,sgd_minibatch_size=128,train_batch_size=1024'},
  path='/Users/hasan.nayir/ray_results/PPO/PPO_teastore_49c0d_00208_208_clip_param=0.2000,entropy_coeff=0,lambda=1,lr=0.0001,sgd_minibatch_size=128,train_batch_size=1024_2024-03-04_06-37-34',
  checkpoint=Checkpoint(local_path=/Users/hasan.nayir/ray_results/PPO/PPO_teastore_49c0d_00208_208_clip_param=0.2000,entropy_coeff=0,lambda=1,lr=0.0001,sgd_minibatch_size=128,train_batch_size=1024_2024-03-04_06-37-34/checkpoint_000250)
)
